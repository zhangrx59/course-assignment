{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcc9ef1a",
   "metadata": {},
   "source": [
    "**<font color = black size=6>实验六:决策树</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba67a4f6",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第一部分:函数介绍</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ac93628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfffb4e",
   "metadata": {},
   "source": [
    "1)Counter类的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85c3787c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({133: 2, 132: 1})\n",
      "0\n",
      "2\n",
      "dict_values([2, 1])\n",
      "[133, 132]\n"
     ]
    }
   ],
   "source": [
    "x=np.array([[0,133,1],[0,132,0],[0,133,0]])\n",
    "#使用Counter类对数组第2列进行遍历\n",
    "counter = Counter(x[:,1])\n",
    "#第2列中有1个132和2个133，输出该counter对象可以统计这列的数值情况，便于之后的统计\n",
    "print(counter)\n",
    "#因为第2列中没有为0的值，所以返回0\n",
    "print(counter[0])\n",
    "#因为第2列中有2个133，所以返回2\n",
    "print(counter[133])\n",
    "#一般的字典操作方法都能在该类中使用，例如可以通过values函数返回该列的非重复值的个数，方便对某列的非重复值的个数进行查看\n",
    "print(counter.values())\n",
    "#可以输出所有非重复值\n",
    "print(list(counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc27d84",
   "metadata": {},
   "source": [
    "2)使用numpy中的unique实现非重复值的提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a954859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1 132 133] [132 133]\n"
     ]
    }
   ],
   "source": [
    "x=np.array([[0,133,1],[0,132,0],[0,133,0]])\n",
    "a=np.unique(x[:])\n",
    "a1=np.unique(x[:,1])\n",
    "print(a,a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b28b2f",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第二部分:实验任务 Part I--编写函数</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbe46fb",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">该数据集(train_titanic.csv)为分类数据集，为泰坦尼克号的部分乘客信息以及最后是否生还。包括了四个属性值以及一个标记属性(即为Survived类型,代表是否生还),属性信息分别为Sex(性别)，sibsp(堂兄弟妹个数)，Parch(父母与小孩的个数)，Pclass(乘客等级)。  \n",
    "其中该数据集无缺失值和异常值，且所有连续变量已自动转换为离散变量,标记(Survived类型)也自动转变为离散变量0和1，所以你无需进行数据预处理，可以直接使用该数据集。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dc6ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9570e618",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">1) 使用pandas库将训练数据集'train_titanic.csv'载入到Dataframe对象中</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1b1263e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sex  sibsp  Parch  Pclass  Survived\n",
      "0       0      1      0       3         0\n",
      "1       1      1      0       1         1\n",
      "2       1      0      0       3         1\n",
      "3       1      1      0       1         1\n",
      "4       0      0      0       3         0\n",
      "...   ...    ...    ...     ...       ...\n",
      "1004    0      0      0       3         0\n",
      "1005    1      0      0       1         0\n",
      "1006    0      0      0       3         0\n",
      "1007    0      0      0       3         0\n",
      "1008    0      1      1       3         0\n",
      "\n",
      "[1009 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# 加载数据集\n",
    "data = pd.read_csv('train_titanic.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f3bc41",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">2) 编写函数，给定任何标记数组计算其信息熵  \n",
    "    输入：标记数组  \n",
    "    输出：该数组对应的信息熵  \n",
    "    计算信息熵公式:\n",
    "某数组包含K个不同的取值，样本为第k(k=1,2,...,K)个值的数量所占比例为p_k,则其信息熵为$$Ent=-\\sum_{k=1}^K p_k log_2 p_k$$</span>\n",
    "    \n",
    "    \n",
    "<span style=\"color:purple\">例:  \n",
    "    输入:[[0],[1]]   \n",
    "    输出:(-$\\frac{1}{2}$ $log_2$ $\\frac{1}{2}$)+(-$\\frac{1}{2}$ $log_2$ $\\frac{1}{2}$)=1</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaa569aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "信息熵是： 0.7709131174627031\n"
     ]
    }
   ],
   "source": [
    "1.\n",
    "#定义计算信息熵函数\n",
    "def calculate_entropy(labels):\n",
    "    label_counts = Counter(labels)\n",
    "    entropy = 0\n",
    "    for count in label_counts.values():\n",
    "        probability = count / len(labels)\n",
    "        entropy -= probability * math.log2(probability)\n",
    "    return entropy\n",
    "#调用函数，求解最后一列列的信息熵\n",
    "features = data.iloc[:, :-1].values  # 特征值\n",
    "labels= data.iloc[:, -1].values      # 标签值\n",
    "print(\"信息熵是：\",calculate_entropy(labels)) # 调用函数计算信息熵"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d77ab84",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">3) 编写函数，函数功能为将所给的数据集按照指定维度dimension进行划分为若干个不同的数据集  \n",
    "    【输入】：属性集合，标记集合，维度索引  \n",
    "    【输出】：划分后所得到的子树属性集合，子树标记集合</span>\n",
    "\n",
    "<span style=\"color:purple\">例子:  \n",
    "    【输入】:feature(属性值集合):[[0,0,0],[0,0,1],[1,0,2]]  \n",
    "    label(标记集合):[[0],[1],[2]]  \n",
    "    划分维度:0</span>  \n",
    "    \n",
    "<span style=\"color:purple\">【输出】:[[0,0,0],[0,0,1]]和[[1,0,2]]  \n",
    "    [[0],[1]]和[[2]]  \n",
    "    tips:即将feature按其第0维度进行划分，由于feature的0维有0和1两个不同的数值，所以feature划分为[[0,0,0],[0,0,1]]和[[1,0,2]]，label划分为[[0],[1]]和[[2]]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f1460ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "2.\n",
    "#定义划分不同数据集函数\n",
    "def split_dataset(features, labels, dimension):\n",
    "    unique_values = np.unique([row[dimension] for row in features])\n",
    "    split_subsets = []\n",
    "    for value in unique_values:\n",
    "        subset = [[], []]  # 第一个列表存放属性，第二个列表存放标记\n",
    "        for i, row in enumerate(features):\n",
    "            if row[dimension] == value:\n",
    "                subset[0].append(row)\n",
    "                subset[1].append(labels[i])\n",
    "        split_subsets.append(subset)\n",
    "    return split_subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b0230f",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">4) 编写函数，函数功能为进行【一次】决策树的结点划分，遍历找出该属性集合中信息增益(使用ID3算法中的公式计算)【最大】的属性  \n",
    "    输入：属性集合，标记集合  \n",
    "    输出：该次划分的最佳信息增益，最佳划分维度  \n",
    "    计算信息增益公式:  \n",
    "    某数据集D有若干属性值以及对应的标记值，其总样本大小为|D|,这里取其中一个属性类型feature,该特征包含V个不同的取值，属性值为第v(v=1,2,...,V)个值的数量为|$D^v$|$(\\sum_{v=1}^V |D^v|=|D|)$,则该属性值对应的信息增益为为$$Gain(D,feature)=Ent(D)-\\sum_{v=1}^V \\frac{|D^v|}{|D|} Ent(D^v)$$\n",
    "所以该函数中你需要计算出每个属性值的信息增益并输出，然后返回最大的信息增益并返回该特征的维数以及最大的信息增益值</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "242439cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "3.\n",
    "#定义信息增益最大的决策划分（ID3算法）\n",
    "def find_best_split_id3(features, labels):\n",
    "    base_entropy = calculate_entropy(labels)\n",
    "    best_gain = 0\n",
    "    best_dimension = -1\n",
    "    num_features = len(features[0])\n",
    "    #遍历\n",
    "    for i in range(num_features):\n",
    "        subsets = split_dataset(features, labels, i)\n",
    "        new_entropy = 0\n",
    "        for subset in subsets:\n",
    "            subset_entropy = calculate_entropy(subset[1])\n",
    "            new_entropy += (len(subset[1]) / len(labels)) * subset_entropy\n",
    "        info_gain = base_entropy - new_entropy\n",
    "        if info_gain > best_gain:\n",
    "            best_gain = info_gain\n",
    "            best_dimension = i\n",
    "    \n",
    "    return best_gain, best_dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f8593e",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">5) 编写函数，函数功能为进行【一次】决策树的结点划分，遍历找出该属性集合中信息增益率(使用C4.5算法中的公式计算)【最大】的属性  \n",
    "    输入：属性集合，标记集合  \n",
    "    输出：该次划分的信息增益率，最佳维度  \n",
    "    计算信息增益率公式:  \n",
    "    某数据集D有若干属性值以及对应的标记值，其总样本大小为|D|,这里取其中一个属性类型feature,该属性包含V个不同的取值，属性值为第v(v=1,2,...,V)个值的数量为|$D^v$|$(\\sum_{v=1}^V|D^v|=|D|)$,该属性本身的信息熵为Ent(feature),则该属性值对应的信息增益率为$$Gain\\_ratio(D,feature)=\\frac{Gain(D,feature)}{Ent(feature)}$$\n",
    "所以该函数中你需要输出每个特征的信息增益率，之后返回最大的信息增益率对应的属性维数以及最大的信息增益率</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91d51379",
   "metadata": {},
   "outputs": [],
   "source": [
    "4.\n",
    "#定义信息增益率最大决策划分（C4.5算法）\n",
    "#需要结合前面的ID3算法和计算信息熵的函数相除\n",
    "def find_best_split_c45(features, labels):\n",
    "    base_entropy = calculate_entropy(labels)\n",
    "    best_gain_ratio = 0\n",
    "    best_dimension = -1\n",
    "    num_features = len(features[0])\n",
    "    \n",
    "    for i in range(num_features):\n",
    "        subsets = split_dataset(features, labels, i)\n",
    "        new_entropy = 0\n",
    "        split_info = 0\n",
    "        for subset in subsets:\n",
    "            subset_entropy = calculate_entropy(subset[1])\n",
    "            proportion = len(subset[1]) / len(labels)\n",
    "            new_entropy += proportion * subset_entropy\n",
    "            split_info -= proportion * math.log2(proportion)\n",
    "        info_gain = base_entropy - new_entropy\n",
    "        if split_info != 0:\n",
    "            gain_ratio = info_gain / split_info\n",
    "            if gain_ratio > best_gain_ratio:\n",
    "                best_gain_ratio = gain_ratio\n",
    "                best_dimension = i\n",
    "    return best_gain_ratio, best_dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee40f45a",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">6) 编写函数，进行【一次】决策树的结点划分，遍历找出该属性集合中基尼系数(使用CART算法中的公式计算)最小的属性以及最佳的划分值  \n",
    "    输入：属性集合，标记集合  \n",
    "    输出：该次划分的最佳的基尼系数，最佳维度，最佳划分值  \n",
    "    计算基尼系数公式:  \n",
    "    某数据集D有若干属性值以及对应的标记值，其总样本大小为|D|,该集合中样本标记类别总共有K类，第k类样本所占比例为$p_k$(k=1,2,..,K)则该数据集对应的基尼系数为$$Gini(D)=1-\\sum_{k=1}^K{p_k}^2$$  \n",
    "    而取其中一个属性类型feature，选定该类型的一个值value，根据feature这个属性是否为value将数据集分为两个子集$D_1$和$D_2$,则该属性feature对应的基尼系数为$$Gini\\_index(D,feature)=\\frac{|D_1|}{|D|}Gini(D_1)+\\frac{|D_2|}{|D|}Gini(D_2)$$\n",
    "所以该函数中你需要首先找出每列中的非重复值，之后根据该列的非重复值进行分类，计算出该列中以该值进行分类的基尼系数，计算出每个属性的每个非重复值的基尼系数，之后找到最小的基尼系数对应的属性维数以及对应的分类值</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d073721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "5.\n",
    "#利用基尼系数进行划分：\n",
    "def find_best_split_cart(features, labels):\n",
    "    best_gini_index = float('inf')\n",
    "    best_dimension = -1\n",
    "    best_split_value = None\n",
    "    num_features = len(features[0])\n",
    "    \n",
    "    for i in range(num_features):\n",
    "        unique_values = np.unique([row[i] for row in features])\n",
    "        for value in unique_values:\n",
    "            subsets = [[], []]  # 分别存储两个子集的标记\n",
    "            for j, row in enumerate(features):\n",
    "                if row[i] == value:\n",
    "                    subsets[0].append(labels[j])\n",
    "                else:\n",
    "                    subsets[1].append(labels[j])\n",
    "            gini_index = sum(\n",
    "                [(len(subset) / len(labels)) * (1 - sum([((subset.count(k) / len(subset)) ** 2) for k in np.unique(subset)])) \n",
    "                 for subset in subsets])\n",
    "            if gini_index < best_gini_index:\n",
    "                best_gini_index = gini_index\n",
    "                best_dimension = i\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_gini_index, best_dimension, best_split_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bdc9f0",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">7) 应用之前你在第4、5、6个部分编写的三个函数，在训练数据集'train_titanic.csv'上依次使用这些函数进行【一次】结点划分，并输出对应的最佳属性维数以及相应的信息增益值/信息增益率/(基尼系数和分类值)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97f82f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "信息熵是： 0.7709131174627031\n",
      "ID3:\n",
      "best_gain: 0.10750711887455178\n",
      "best_dimension: 0\n",
      "C4.5:\n",
      "best_gain: 0.10750711887455178\n",
      "best_dimension: 0\n",
      "GINI:\n",
      "best_gini_index: 0.2964915724641573\n",
      "best_dimension: 0\n",
      "best_split: 0\n"
     ]
    }
   ],
   "source": [
    "7.\n",
    "#实现一次划分\n",
    "features = data.iloc[:, :-1].values  # 特征值\n",
    "labels= data.iloc[:, -1].values      # 标签值\n",
    "print(\"信息熵是：\",calculate_entropy(labels)) # 调用函数计算信息熵\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#使用ID3算法进行信息划分：\n",
    "best_gain, best_dimension=find_best_split_id3(features, labels)       #ID3算法\n",
    "print(\"ID3:\")\n",
    "print(\"best_gain:\",best_gain)\n",
    "print(\"best_dimension:\",best_dimension)\n",
    "\n",
    "\n",
    "#使用C4.5算法进行信息划分：\n",
    "best_gain_ratio, best_dimension2=find_best_split_c45(features, labels)\n",
    "print(\"C4.5:\")\n",
    "print(\"best_gain:\",best_gain)\n",
    "print(\"best_dimension:\",best_dimension)\n",
    "\n",
    "\n",
    "#使用gini函数进行信息划分：\n",
    "best_gini_index, best_dimension3, best_split=find_best_split_cart(features, labels)\n",
    "print(\"GINI:\")\n",
    "print(\"best_gini_index:\",best_gini_index)\n",
    "print(\"best_dimension:\",best_dimension)\n",
    "print(\"best_split:\",best_split)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
