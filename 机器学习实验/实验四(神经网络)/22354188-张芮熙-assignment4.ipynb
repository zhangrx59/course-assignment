{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e59a56ee",
   "metadata": {},
   "source": [
    "**<font color = black size=6>实验四：神经网络中的前向传播与后向传播</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "62f100c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebaf0fe",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第一部分:PyTorch介绍</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a394db6",
   "metadata": {},
   "source": [
    "这里介绍一小部分PyTorch常用的库和函数，更多需求可参阅[PyTorch官方教程](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)以及[PyTorch官方文档](https://pytorch.org/docs/stable/index.html)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6fae149b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch # 导入的是 torch 而不是 pytorch\n",
    "print(torch.__version__) # 输出当前pytorch的版本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392780bb",
   "metadata": {},
   "source": [
    "1.Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904623e4",
   "metadata": {},
   "source": [
    "Tensor与NumPy中的ndarray很相似，但Tensor可以利用GPU来加速计算（虽然本门课不用）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23642996",
   "metadata": {},
   "source": [
    "1.1. Tensor的创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "38cdf3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[0.4537, 0.4752, 0.2058, 0.3054],\n",
      "        [0.9185, 0.4878, 0.0036, 0.1652],\n",
      "        [0.6361, 0.7840, 0.3336, 0.3593]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个未初始化的Tensor\n",
    "x = torch.empty(2, 3)\n",
    "print(x)\n",
    "\n",
    "# 从一个列表创建Tensor\n",
    "x = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(x)\n",
    "\n",
    "# 创建一个随机Tensor\n",
    "x = torch.rand([3, 4])\n",
    "print(x)\n",
    "\n",
    "# 创建一个全零Tensor\n",
    "x = torch.zeros([2, 3])\n",
    "print(x)\n",
    "\n",
    "# 创建一个全一Tensor\n",
    "x = torch.ones([2, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f354fd4",
   "metadata": {},
   "source": [
    "1.2. Tensor的运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8070a903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 7, 7],\n",
      "        [7, 7, 7]])\n",
      "tensor([[-5, -3, -1],\n",
      "        [ 1,  3,  5]])\n",
      "tensor([[ 6, 10, 12],\n",
      "        [12, 10,  6]])\n",
      "tensor([[ 6, 10, 12],\n",
      "        [12, 10,  6]])\n",
      "tensor([[28, 10],\n",
      "        [73, 28]])\n",
      "tensor([[28, 10],\n",
      "        [73, 28]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [6, 5, 4],\n",
      "        [3, 2, 1]])\n",
      "tensor([[1, 2, 3, 6, 5, 4],\n",
      "        [4, 5, 6, 3, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "# 加减法\n",
    "x = torch.tensor([[1,2,3],[4,5,6]])\n",
    "y = torch.tensor([[6,5,4],[3,2,1]])\n",
    "print(x + y)\n",
    "print(x - y)\n",
    "\n",
    "# 对应位置相乘\n",
    "print(x * y)\n",
    "print(x.mul(y))\n",
    "\n",
    "# 矩阵乘法\n",
    "print(x.matmul(y.T))\n",
    "print(x @ y.T)\n",
    "\n",
    "# reshape\n",
    "print(x.reshape(3, 2))\n",
    "\n",
    "# 拼接\n",
    "print(torch.cat([x,y], dim=0)) # 纵向拼接\n",
    "print(torch.cat([x,y], dim=1)) # 横向拼接"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95961cee",
   "metadata": {},
   "source": [
    "1.3. Tensor与ndarray的相互转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d1269212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "[[0 0 0]\n",
      " [0 0 0]]\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(x)\n",
    "\n",
    "# 从Tensor转换到ndarray\n",
    "y = x.numpy()\n",
    "print(y)\n",
    "\n",
    "# Tensor与ndarray是共享空间的\n",
    "x[:]=0\n",
    "print(y)\n",
    "\n",
    "# 从ndarray到Tensor\n",
    "z = torch.from_numpy(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c36a7",
   "metadata": {},
   "source": [
    "2.自动求梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3b30fec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 4.]]) tensor(1.)\n",
      "tensor([0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966,\n",
      "        0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966,\n",
      "        0.1966, 0.1966])\n",
      "tensor(4.)\n",
      "tensor(5.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1.,2.]], requires_grad=True) # 把requires_grad设为True, 开始跟踪基于它的所有运算\n",
    "b = torch.tensor([[3.],[4.]])\n",
    "c = torch.tensor(5., requires_grad=True)\n",
    "y = a @ b + c\n",
    "y.backward() #自动计算梯度\n",
    "print(a.grad, c.grad) #输出叶子节点a和c的梯度\n",
    "\n",
    "# 可支持多种运算求梯度，如torch.mean(),torch.sum()等\n",
    "a = torch.ones(20, requires_grad=True)\n",
    "z = torch.sum(torch.sigmoid(a))\n",
    "z.backward()\n",
    "print(a.grad)\n",
    "\n",
    "# 多次求梯度时梯度会累加，可使用tensor.grad.zero_()进行手动清零\n",
    "x = torch.tensor(2., requires_grad=True)\n",
    "y = x ** 2\n",
    "y.backward()\n",
    "print(x.grad)\n",
    "z = x + 3\n",
    "z.backward()\n",
    "print(x.grad)\n",
    "x.grad.zero_()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d22808",
   "metadata": {},
   "source": [
    "3. 神经网络（官方教程中的例子）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "207b6433",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 继承自nn.Module\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 卷积层\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        # nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)\n",
    "        # 其中in_features表示有多少个输入，out_features表示该层有多少个神经元\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6c2a943f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "# 该神经网络中可学习的参数可以通过net.parameters()访问\n",
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b733263e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0279, -0.0320,  0.0505, -0.0042, -0.0875, -0.0619,  0.0767, -0.0196,\n",
      "          0.0097,  0.0287]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 随机生成一个输入送入net中，除了第0维是样本个数外，其余维度要与forward()参数中x的维度对应上\n",
    "input = torch.randn(1, 1, 32, 32) # 1个样本，该样本是有1个通道的32×32的图像\n",
    "out = net(input) # 进行一次forward()前向传播\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "168659b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad() # 手动清零神经网络中参数的梯度\n",
    "out.backward(torch.randn(1, 10)) # 用随机梯度进行一次backward()后向传播来计算梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "af35f14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3370, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "# nn模块提供了许多种类的损失函数，如nn.CrossEntropyLoss()、nn.MSELoss()等等\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1428f7ce",
   "metadata": {},
   "source": [
    "计算图如下：\n",
    "input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
    "      -> flatten -> linear -> relu -> linear -> relu -> linear\n",
    "      -> MSELoss\n",
    "      -> loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e9ada5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward0 object at 0x000002167E807C40>\n",
      "<AddmmBackward0 object at 0x000002167E807610>\n",
      "<AccumulateGrad object at 0x000002167E807C40>\n"
     ]
    }
   ],
   "source": [
    "# 查看计算图中的函数\n",
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "854ee4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "None\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0041, -0.0018,  0.0104,  0.0061, -0.0167,  0.0003])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "# 进行一次后向传播\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d7187507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用梯度下降法(手动)更新net中的参数\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "06d237aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用PyTorch的优化器来更新net中的参数\n",
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# 在每次循环中应该做的事:\n",
    "optimizer.zero_grad()   # 把梯度清零\n",
    "output = net(input) # 进行一次前向传播\n",
    "loss = criterion(output, target) # 计算误差\n",
    "loss.backward() # 后向传播\n",
    "optimizer.step()    # 参数更新"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50be2d1f",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第二部分:实验内容</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5214e5",
   "metadata": {},
   "source": [
    "[Red Wine Quality](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009)是一个关于红酒品质的数据集，总共有1599个样本，每个样本包含11个(都是连续的)特征以及1个标签，每个标签的取值是连续的。本次实验已经按照8：2的比例划分成了训练数据集'wine_train.csv'以及测试数据集'wine_test.csv'，且每个数据集都已经做了归一化处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d9ccac",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">1) 读入训练数据集'wine_train.csv'与测试数据集'wine_test.csv'。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c759660f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4 0.6 0.8 ... 0.6 0.4 0.4]\n",
      "[0.6 0.2 0.6 0.4 0.6 0.4 0.8 0.4 0.8 0.6 0.4 0.6 0.4 0.6 0.6 0.8 0.4 0.4\n",
      " 0.4 0.6 0.6 0.  0.4 0.8 0.6 0.6 0.8 0.6 0.4 0.6 0.4 0.4 0.4 0.8 0.4 0.8\n",
      " 0.6 0.6 0.6 0.4 0.4 0.2 0.6 0.4 0.6 0.4 0.4 0.6 0.8 0.6 0.8 0.6 0.6 0.4\n",
      " 0.6 0.8 0.4 0.4 0.6 0.8 0.6 0.6 1.  0.4 0.4 0.4 0.6 0.6 0.6 0.4 0.4 0.6\n",
      " 0.4 0.4 0.8 0.4 0.6 0.4 0.6 0.8 0.4 0.8 0.6 0.4 0.6 0.4 0.4 0.4 0.6 0.4\n",
      " 0.6 0.4 0.4 0.6 0.6 0.4 0.4 0.6 0.4 0.6 0.6 0.6 0.6 0.6 0.4 0.4 0.6 0.6\n",
      " 0.4 0.2 0.6 0.8 0.6 0.4 0.6 0.6 0.8 0.6 0.6 0.8 0.6 0.4 0.4 0.2 0.4 0.8\n",
      " 0.6 0.4 0.6 0.4 0.6 0.6 0.6 0.8 1.  0.4 0.4 0.4 0.4 0.8 0.4 0.4 0.6 0.4\n",
      " 0.6 0.4 0.2 0.4 0.6 0.4 0.4 0.4 0.6 0.6 0.6 0.4 0.4 0.8 0.6 0.4 0.4 0.4\n",
      " 0.8 0.6 0.8 0.4 0.4 0.8 0.8 0.6 0.4 0.4 0.4 0.6 0.8 0.8 0.4 0.4 0.4 0.6\n",
      " 0.8 0.4 0.6 0.8 0.4 0.8 0.6 0.4 0.4 0.4 0.8 0.6 0.8 0.8 0.6 0.4 0.6 0.4\n",
      " 0.6 0.4 0.6 0.4 0.6 0.4 0.8 0.4 0.8 0.4 0.6 0.6 0.4 0.6 0.8 0.6 0.4 0.4\n",
      " 0.4 0.4 0.6 0.6 0.4 0.6 0.4 0.6 0.8 0.8 0.4 0.6 0.4 0.8 0.6 0.4 0.4 0.4\n",
      " 0.4 0.4 0.4 0.6 0.6 0.6 0.6 0.4 0.6 0.4 0.4 0.8 0.4 0.6 0.6 0.4 0.6 0.4\n",
      " 0.4 0.8 0.4 0.4 0.4 0.4 0.4 0.8 0.4 0.4 0.6 0.6 0.  0.6 0.2 0.  0.4 0.4\n",
      " 0.8 0.8 0.6 0.4 0.4 0.2 0.6 0.4 0.8 0.6 0.6 0.4 0.4 0.4 0.6 0.6 0.4 0.4\n",
      " 0.6 0.8 0.4 0.6 0.6 0.6 0.8 0.4 0.4 0.6 0.4 0.4 0.6 0.4 0.6 0.4 0.2 0.6\n",
      " 0.4 0.4 0.6 0.6 0.6 0.6 0.4 0.8 0.4 0.6 0.6 0.4 0.4 0.4]\n",
      "1279\n",
      "320\n"
     ]
    }
   ],
   "source": [
    "# -- Your code here --\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "# 读入数据\n",
    "train_data = pd.read_csv('wine_train.csv')\n",
    "test_data = pd.read_csv('wine_test.csv')\n",
    "# 分离特征和标签\n",
    "X_train = train_data.iloc[:, :-1].values  # 所有行，除了最后一列的数据\n",
    "y_train = train_data.iloc[:, -1].values  # 所有行，只有最后一列的数据\n",
    "\n",
    "X_test = test_data.iloc[:, :-1].values\n",
    "y_test = test_data.iloc[:, -1].values\n",
    "print(y_train)\n",
    "print(y_test)\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77619fd",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">2) 利用线性层和激活函数搭建一个神经网络，要求输入和输出维度与数据集维度一致，而神经网络深度、隐藏层大小、激活函数种类等超参数自行调整。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "26359bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Your code here --\n",
    "# 定义网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(11, 12)  # 输入层到隐藏层1\n",
    "        self.fc2 = nn.Linear(12, 12)#隐藏层1到隐藏层2\n",
    "        self.fc3 = nn.Linear(12, 1)   # 隐藏层2到输出层\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))  # 激活函数为ReLU\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "# 转换数据为torch张量\n",
    "X_train_torch = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_torch = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)  \n",
    "# 调整形状以匹配输出（只有一个标签值）\n",
    "X_test_torch = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_torch = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b706eea",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">3) 用梯度下降法进行模型参数更新，记下每轮迭代中的训练损失和测试损失。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cad2f094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.25737208127975464, Test Loss: 0.2474537342786789\n",
      "Epoch 2/100, Training Loss: 0.24325941503047943, Test Loss: 0.2338804006576538\n",
      "Epoch 3/100, Training Loss: 0.22998593747615814, Test Loss: 0.2211264669895172\n",
      "Epoch 4/100, Training Loss: 0.2174992561340332, Test Loss: 0.20913347601890564\n",
      "Epoch 5/100, Training Loss: 0.205754354596138, Test Loss: 0.19785836338996887\n",
      "Epoch 6/100, Training Loss: 0.19470998644828796, Test Loss: 0.18725840747356415\n",
      "Epoch 7/100, Training Loss: 0.18432529270648956, Test Loss: 0.17729365825653076\n",
      "Epoch 8/100, Training Loss: 0.1745545119047165, Test Loss: 0.1679253876209259\n",
      "Epoch 9/100, Training Loss: 0.16536477208137512, Test Loss: 0.15912042558193207\n",
      "Epoch 10/100, Training Loss: 0.1567249745130539, Test Loss: 0.15084345638751984\n",
      "Epoch 11/100, Training Loss: 0.14860069751739502, Test Loss: 0.14305968582630157\n",
      "Epoch 12/100, Training Loss: 0.14095672965049744, Test Loss: 0.13573995232582092\n",
      "Epoch 13/100, Training Loss: 0.13376468420028687, Test Loss: 0.1288560926914215\n",
      "Epoch 14/100, Training Loss: 0.12699665129184723, Test Loss: 0.1223858967423439\n",
      "Epoch 15/100, Training Loss: 0.1206342801451683, Test Loss: 0.11630769819021225\n",
      "Epoch 16/100, Training Loss: 0.11465388536453247, Test Loss: 0.11059751361608505\n",
      "Epoch 17/100, Training Loss: 0.10903162509202957, Test Loss: 0.10522903501987457\n",
      "Epoch 18/100, Training Loss: 0.1037444919347763, Test Loss: 0.1001846045255661\n",
      "Epoch 19/100, Training Loss: 0.09877321124076843, Test Loss: 0.09545072913169861\n",
      "Epoch 20/100, Training Loss: 0.094106025993824, Test Loss: 0.0910080298781395\n",
      "Epoch 21/100, Training Loss: 0.08972584456205368, Test Loss: 0.08684156835079193\n",
      "Epoch 22/100, Training Loss: 0.08561664819717407, Test Loss: 0.08293417096138\n",
      "Epoch 23/100, Training Loss: 0.08176073431968689, Test Loss: 0.07926821708679199\n",
      "Epoch 24/100, Training Loss: 0.07813923805952072, Test Loss: 0.07582943141460419\n",
      "Epoch 25/100, Training Loss: 0.07473953813314438, Test Loss: 0.07260453701019287\n",
      "Epoch 26/100, Training Loss: 0.07155001163482666, Test Loss: 0.06957747787237167\n",
      "Epoch 27/100, Training Loss: 0.0685582086443901, Test Loss: 0.06673658639192581\n",
      "Epoch 28/100, Training Loss: 0.06575136631727219, Test Loss: 0.06407412141561508\n",
      "Epoch 29/100, Training Loss: 0.0631200447678566, Test Loss: 0.06158145144581795\n",
      "Epoch 30/100, Training Loss: 0.06065552309155464, Test Loss: 0.059248607605695724\n",
      "Epoch 31/100, Training Loss: 0.058347199112176895, Test Loss: 0.05706416815519333\n",
      "Epoch 32/100, Training Loss: 0.05618441104888916, Test Loss: 0.055018842220306396\n",
      "Epoch 33/100, Training Loss: 0.05415843054652214, Test Loss: 0.05310569331049919\n",
      "Epoch 34/100, Training Loss: 0.0522625632584095, Test Loss: 0.051315438002347946\n",
      "Epoch 35/100, Training Loss: 0.05048757046461105, Test Loss: 0.049641527235507965\n",
      "Epoch 36/100, Training Loss: 0.048827171325683594, Test Loss: 0.04807617515325546\n",
      "Epoch 37/100, Training Loss: 0.047273751348257065, Test Loss: 0.04661356657743454\n",
      "Epoch 38/100, Training Loss: 0.04582175612449646, Test Loss: 0.045246802270412445\n",
      "Epoch 39/100, Training Loss: 0.04446389526128769, Test Loss: 0.04396896809339523\n",
      "Epoch 40/100, Training Loss: 0.043192919343709946, Test Loss: 0.04277566820383072\n",
      "Epoch 41/100, Training Loss: 0.04200558364391327, Test Loss: 0.04166161268949509\n",
      "Epoch 42/100, Training Loss: 0.040896084159612656, Test Loss: 0.04062154144048691\n",
      "Epoch 43/100, Training Loss: 0.03985951468348503, Test Loss: 0.039650846272706985\n",
      "Epoch 44/100, Training Loss: 0.03889140486717224, Test Loss: 0.03874509409070015\n",
      "Epoch 45/100, Training Loss: 0.03798738867044449, Test Loss: 0.03790014237165451\n",
      "Epoch 46/100, Training Loss: 0.03714348375797272, Test Loss: 0.037111978977918625\n",
      "Epoch 47/100, Training Loss: 0.03635574132204056, Test Loss: 0.03637636452913284\n",
      "Epoch 48/100, Training Loss: 0.035620588809251785, Test Loss: 0.03569037839770317\n",
      "Epoch 49/100, Training Loss: 0.03493454307317734, Test Loss: 0.03505079820752144\n",
      "Epoch 50/100, Training Loss: 0.034294359385967255, Test Loss: 0.03445436805486679\n",
      "Epoch 51/100, Training Loss: 0.0336964949965477, Test Loss: 0.033898163586854935\n",
      "Epoch 52/100, Training Loss: 0.03313840180635452, Test Loss: 0.03337935358285904\n",
      "Epoch 53/100, Training Loss: 0.032617781311273575, Test Loss: 0.032895278185606\n",
      "Epoch 54/100, Training Loss: 0.032132234424352646, Test Loss: 0.032444246113300323\n",
      "Epoch 55/100, Training Loss: 0.031679410487413406, Test Loss: 0.032023780047893524\n",
      "Epoch 56/100, Training Loss: 0.03125695884227753, Test Loss: 0.031632110476493835\n",
      "Epoch 57/100, Training Loss: 0.030863068997859955, Test Loss: 0.031267277896404266\n",
      "Epoch 58/100, Training Loss: 0.03049580007791519, Test Loss: 0.030927497893571854\n",
      "Epoch 59/100, Training Loss: 0.030153386294841766, Test Loss: 0.030611073598265648\n",
      "Epoch 60/100, Training Loss: 0.029834160581231117, Test Loss: 0.030316341668367386\n",
      "Epoch 61/100, Training Loss: 0.029536500573158264, Test Loss: 0.030041879042983055\n",
      "Epoch 62/100, Training Loss: 0.029259024187922478, Test Loss: 0.029786327853798866\n",
      "Epoch 63/100, Training Loss: 0.02900032512843609, Test Loss: 0.029548317193984985\n",
      "Epoch 64/100, Training Loss: 0.028759056702256203, Test Loss: 0.029326658695936203\n",
      "Epoch 65/100, Training Loss: 0.028534090146422386, Test Loss: 0.029120227321982384\n",
      "Epoch 66/100, Training Loss: 0.028324369341135025, Test Loss: 0.028928007930517197\n",
      "Epoch 67/100, Training Loss: 0.02812882885336876, Test Loss: 0.028749030083417892\n",
      "Epoch 68/100, Training Loss: 0.027946487069129944, Test Loss: 0.028582334518432617\n",
      "Epoch 69/100, Training Loss: 0.027776429429650307, Test Loss: 0.028427090495824814\n",
      "Epoch 70/100, Training Loss: 0.027617858722805977, Test Loss: 0.028282513841986656\n",
      "Epoch 71/100, Training Loss: 0.02746998332440853, Test Loss: 0.028147852048277855\n",
      "Epoch 72/100, Training Loss: 0.02733207866549492, Test Loss: 0.028022397309541702\n",
      "Epoch 73/100, Training Loss: 0.027203448116779327, Test Loss: 0.027905503287911415\n",
      "Epoch 74/100, Training Loss: 0.027083437889814377, Test Loss: 0.027796611189842224\n",
      "Epoch 75/100, Training Loss: 0.026971446350216866, Test Loss: 0.027695149183273315\n",
      "Epoch 76/100, Training Loss: 0.026866937056183815, Test Loss: 0.027600575238466263\n",
      "Epoch 77/100, Training Loss: 0.026769373565912247, Test Loss: 0.02751239575445652\n",
      "Epoch 78/100, Training Loss: 0.026678266003727913, Test Loss: 0.027430156245827675\n",
      "Epoch 79/100, Training Loss: 0.026593158021569252, Test Loss: 0.027353446930646896\n",
      "Epoch 80/100, Training Loss: 0.026513660326600075, Test Loss: 0.027281884104013443\n",
      "Epoch 81/100, Training Loss: 0.026439383625984192, Test Loss: 0.027214908972382545\n",
      "Epoch 82/100, Training Loss: 0.026369960978627205, Test Loss: 0.027152229100465775\n",
      "Epoch 83/100, Training Loss: 0.026305055245757103, Test Loss: 0.02709365263581276\n",
      "Epoch 84/100, Training Loss: 0.02624434232711792, Test Loss: 0.027038896456360817\n",
      "Epoch 85/100, Training Loss: 0.02618752419948578, Test Loss: 0.02698769047856331\n",
      "Epoch 86/100, Training Loss: 0.026134338229894638, Test Loss: 0.02693977579474449\n",
      "Epoch 87/100, Training Loss: 0.026084527373313904, Test Loss: 0.026894912123680115\n",
      "Epoch 88/100, Training Loss: 0.02603786438703537, Test Loss: 0.026852872222661972\n",
      "Epoch 89/100, Training Loss: 0.025994105264544487, Test Loss: 0.026813466101884842\n",
      "Epoch 90/100, Training Loss: 0.025953052565455437, Test Loss: 0.026776498183608055\n",
      "Epoch 91/100, Training Loss: 0.025914527475833893, Test Loss: 0.02674177661538124\n",
      "Epoch 92/100, Training Loss: 0.0258783008903265, Test Loss: 0.026709115132689476\n",
      "Epoch 93/100, Training Loss: 0.025844212621450424, Test Loss: 0.02667839452624321\n",
      "Epoch 94/100, Training Loss: 0.025812141597270966, Test Loss: 0.02664947137236595\n",
      "Epoch 95/100, Training Loss: 0.025781936943531036, Test Loss: 0.026622211560606956\n",
      "Epoch 96/100, Training Loss: 0.025753486901521683, Test Loss: 0.026596451178193092\n",
      "Epoch 97/100, Training Loss: 0.02572666108608246, Test Loss: 0.026572123169898987\n",
      "Epoch 98/100, Training Loss: 0.025701332837343216, Test Loss: 0.026549112051725388\n",
      "Epoch 99/100, Training Loss: 0.025677401572465897, Test Loss: 0.02652733586728573\n",
      "Epoch 100/100, Training Loss: 0.025654755532741547, Test Loss: 0.026506688445806503\n"
     ]
    }
   ],
   "source": [
    "# -- Your code here --\n",
    "# 损失函数和优化器\n",
    "criterion = nn.MSELoss()  # 均方误差\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)  # 随机梯度下降\n",
    "\n",
    "# 记录损失\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# 训练过程\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()   # 清除旧的梯度\n",
    "    outputs = net(X_train_torch)  # 前向传播\n",
    "    loss = criterion(outputs, y_train_torch)  # 计算损失\n",
    "    loss.backward()  # 反向传播\n",
    "    optimizer.step()  # 更新权重\n",
    "    train_losses.append(loss.item())# 记录训练损失\n",
    "\n",
    "    # 测试损失\n",
    "    with torch.no_grad():  # 确保不会计算梯度\n",
    "        outputs_test = net(X_test_torch)\n",
    "        loss_test = criterion(outputs_test, y_test_torch)\n",
    "        test_losses.append(loss_test.item())\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {loss.item()}, Test Loss: {loss_test.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5ff45e",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">4) 画出训练损失和测试损失关于迭代轮数的折线图。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3ba3071f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- Your code here --\n",
    "# 绘制损失曲线\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()#显示标签\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
